{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e2108625",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing required packages\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from typing import TypedDict, Annotated\n",
    "\n",
    "from langchain_huggingface import HuggingFaceEndpoint, ChatHuggingFace\n",
    "from langchain_perplexity import ChatPerplexity\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "import operator\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "255d925d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Initiating the environment\n",
    "# load_dotenv()\n",
    "\n",
    "# ## Defining and initiating llm\n",
    "# llm = HuggingFaceEndpoint(\n",
    "#     repo_id= 'meta-llama/Llama-3.3-70B-Instruct'\n",
    "#     )\n",
    "\n",
    "# model = ChatHuggingFace(llm = llm)\n",
    "\n",
    "# ## Instead of using lighter model - 'meta-llama/Llama-3.2-1B-Instruct', we are using the heavier model - 'meta-llama/Llama-3.3-70B-Instruct' as this only supports function calling for structured output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "48be00c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Since HuggingFace models does not support .with_structured_output() menthod, therefore for this specific use case we are using Perplexity's sonar model.\n",
    "\n",
    "## Initiating the environment\n",
    "load_dotenv()\n",
    "\n",
    "## Defining and initiating llm\n",
    "model = ChatPerplexity(\n",
    "    model= 'sonar', api_key= os.getenv(\"PERPLEXITY_API_KEY\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "04566187",
   "metadata": {},
   "outputs": [],
   "source": [
    "## To get the structuree output from the model, we need to define a schema and pass it to the model so that it can understand\n",
    "class EvaluationSchema(BaseModel):\n",
    "    feedback: str = Field(description= 'Detailed feedback for the essay')\n",
    "    score: int =  Field(description= 'Score out of 10', ge=0, le=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "17de12c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Defining structured output model\n",
    "structured_model = model.with_structured_output(EvaluationSchema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "82b357fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Defining the essay\n",
    "\n",
    "essay = \"\"\"India in the Age of AI\n",
    "As the world enters a transformative era defined by artificial intelligence (AI), India stands at a critical juncture — one where it can either emerge as a global leader in AI innovation or risk falling behind in the technology race. The age of AI brings with it immense promise as well as unprecedented challenges, and how India navigates this landscape will shape its socio-economic and geopolitical future.\n",
    "\n",
    "India's strengths in the AI domain are rooted in its vast pool of skilled engineers, a thriving IT industry, and a growing startup ecosystem. With over 5 million STEM graduates annually and a burgeoning base of AI researchers, India possesses the intellectual capital required to build cutting-edge AI systems. Institutions like IITs, IIITs, and IISc have begun fostering AI research, while private players such as TCS, Infosys, and Wipro are integrating AI into their global services. In 2020, the government launched the National AI Strategy (AI for All) with a focus on inclusive growth, aiming to leverage AI in healthcare, agriculture, education, and smart mobility.\n",
    "\n",
    "One of the most promising applications of AI in India lies in agriculture, where predictive analytics can guide farmers on optimal sowing times, weather forecasts, and pest control. In healthcare, AI-powered diagnostics can help address India’s doctor-patient ratio crisis, particularly in rural areas. Educational platforms are increasingly using AI to personalize learning paths, while smart governance tools are helping improve public service delivery and fraud detection.\n",
    "\n",
    "However, the path to AI-led growth is riddled with challenges. Chief among them is the digital divide. While metropolitan cities may embrace AI-driven solutions, rural India continues to struggle with basic internet access and digital literacy. The risk of job displacement due to automation also looms large, especially for low-skilled workers. Without effective skilling and re-skilling programs, AI could exacerbate existing socio-economic inequalities.\n",
    "\n",
    "Another pressing concern is data privacy and ethics. As AI systems rely heavily on vast datasets, ensuring that personal data is used transparently and responsibly becomes vital. India is still shaping its data protection laws, and in the absence of a strong regulatory framework, AI systems may risk misuse or bias.\n",
    "\n",
    "To harness AI responsibly, India must adopt a multi-stakeholder approach involving the government, academia, industry, and civil society. Policies should promote open datasets, encourage responsible innovation, and ensure ethical AI practices. There is also a need for international collaboration, particularly with countries leading in AI research, to gain strategic advantage and ensure interoperability in global systems.\n",
    "\n",
    "India’s demographic dividend, when paired with responsible AI adoption, can unlock massive economic growth, improve governance, and uplift marginalized communities. But this vision will only materialize if AI is seen not merely as a tool for automation, but as an enabler of human-centered development.\n",
    "\n",
    "In conclusion, India in the age of AI is a story in the making — one of opportunity, responsibility, and transformation. The decisions we make today will not just determine India’s AI trajectory, but also its future as an inclusive, equitable, and innovation-driven society.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ba71793b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The essay \"India in the Age of AI\" demonstrates a strong command of language appropriate for an academic and analytical piece. The vocabulary is precise and formal, fitting the subject matter well. The style is coherent and structured, with clear paragraphing that logically develops the argument across introduction, body, and conclusion. Sentences vary in length and complexity, which aids readability without sacrificing sophistication. The essay avoids colloquialisms or overly casual expressions, maintaining an objective and balanced tone throughout, in line with academic conventions. The author successfully integrates technical terms related to AI and socio-economic contexts, explaining their relevance clearly. Minor improvements could include slightly more explicit signposting of the thesis early on and a few transitions to enhance flow between some paragraphs. Overall, the language quality effectively supports the essay’s analytical depth and critical engagement with the topic, reflecting excellent academic writing standards.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Defining prompt and invoking model\n",
    "prompt = f'Evaluate the language quality of the following essay and provide a feedback and assign a score out of 10 \\n {essay}'\n",
    "structured_model.invoke(prompt).feedback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca39b20",
   "metadata": {},
   "source": [
    "Cool, we have our model that returns the response as we wants. Now, lets just define the state and build the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ef7403bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Defining the state\n",
    "class UPSCState(StateGraph):\n",
    "\n",
    "    essay: str\n",
    "    language_feedback : str\n",
    "    analysis_fedback: str\n",
    "    clarity_feedback : str\n",
    "    overall_feedback : str\n",
    "\n",
    "    individual_scores : Annotated[list[int], operator.add]\n",
    "    avg_score : float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a72c0ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_language(state: UPSCState) -> UPSCState:\n",
    "    essay = state['essay']\n",
    "    prompt = f'Evaluate the language quality of the following essay and provide a feedback and assign a score out of 10 \\n {essay}'\n",
    "\n",
    "    output = structured_model.invoke(prompt)\n",
    "    return {'language_feedback' : output.feedback, 'individual_scores' : [output.score]}\n",
    "\n",
    "\n",
    "def evaluate_analysis(state: UPSCState) -> UPSCState:\n",
    "    essay = state['essay']\n",
    "    prompt = f'Evaluate the depth of analysis of the following essay and provide a feedback and assign a score out of 10 \\n {essay}'\n",
    "\n",
    "    output = structured_model.invoke(prompt)\n",
    "    return {'analysis_feedback' : output.feedback, 'individual_scores' : [output.score]}\n",
    "\n",
    "def evaluate_thought(state: UPSCState) -> UPSCState:\n",
    "    essay = state['essay']\n",
    "    prompt = f'Evaluate the clarity of thought of the following essay and provide a feedback and assign a score out of 10 \\n {essay}'\n",
    "\n",
    "    output = structured_model.invoke(prompt)\n",
    "    return {'clarity_feedback' : output.feedback, 'individual_scores' : [output.score]}\n",
    "\n",
    "def final_evaluation(state: UPSCState):\n",
    "    # summary feedback\n",
    "    prompt = f'Based on the following feedbacks create a summarized feedback \\n language feedback - {state[\"language_feedback\"]} \\n depth of analysis feedback - {state[\"analysis_feedback\"]} \\n clarity of thought feedback - {state[\"clarity_feedback\"]}'\n",
    "    overall_feedback = model.invoke(prompt).content\n",
    "\n",
    "    # avg calculate\n",
    "    avg_score = sum(state['individual_scores'])/len(state['individual_scores'])\n",
    "\n",
    "    return {'overall_feedback': overall_feedback, 'avg_score': avg_score}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3d85e38c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x2532c3a7b50>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Defining the graph\n",
    "graph = StateGraph(UPSCState)\n",
    "\n",
    "## Add nodes\n",
    "graph.add_node('evaluate_language', evaluate_language)\n",
    "graph.add_node('evalueate_analysis', evaluate_analysis)\n",
    "graph.add_node('evalueate_thought', evaluate_thought)\n",
    "graph.add_node('final_evaluation', final_evaluation)\n",
    "\n",
    "## Add edges\n",
    "\n",
    "## Model compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58b6023",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
